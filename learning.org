#+TITLE: Learning
* Introduction

This project is an experiment.  I'd like to add a bit more structure
to the things I know and the things I'm interested in learning about.
Maybe a notebook would be better; maybe not.

I'm not sure how I'm going to incorporate images and diagrams into
this notebook (to make it a more visual experience) but we'll see how
far I can get.


* Viewing on GitHub

I have not researched how to make all the links that work just fine in
org-mode in Emacs work at all on GitHub.  To best view this document,
clone this repo and open learning.org in Emacs (assuming you have
org-mode installed).


* Topics

These are some of the topics I'm interested in learning more about.

** Algorithms

*** To Learn About [0/26]

**** TODO [[http://arxiv.org/abs/cs/0011047][Dancing Links (Knuth)]]
**** TODO [[http://citeseerx.ist.psu.edu/viewdoc/summary?doi%3D10.1.1.34.1317][Persistent Arrays]]
**** TODO [[http://en.wikipedia.org/wiki/Binary_search_algorithm][Binary Search]]
**** TODO [[http://en.wikipedia.org/wiki/Bucket_sort][Bucket Sort]]
**** TODO [[http://en.wikipedia.org/wiki/Cantor%2527s_diagonal_argument][Cantor's Diagonal Argument]]
**** TODO [[http://en.wikipedia.org/wiki/Cycle_detection][Cycle Detection]]
**** TODO [[http://en.wikipedia.org/wiki/Dijkstra%2527s_algorithm][Dijkstra's Algorithm]]
**** TODO [[http://en.wikipedia.org/wiki/Disjoint-set_data_structure][Disjoint-set data structure]]
**** TODO [[http://en.wikipedia.org/wiki/Euclidean_algorithm][Euclidean Algorithm]]
**** TODO [[http://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm][Floyd-Warshall]]
**** TODO [[http://en.wikipedia.org/wiki/Hash_consing][Hash Consing]]
**** TODO [[http://en.wikipedia.org/wiki/Horner_scheme][Horner Scheme]]
**** TODO [[http://en.wikipedia.org/wiki/Knuth%E2%80%93Bendix_completion_algorithm][Knuth-Bendix Algorithm]]
**** TODO [[http://en.wikipedia.org/wiki/Linear_programming#Algorithms][Linear Programming Algorithms]]
**** TODO [[http://en.wikipedia.org/wiki/Reed_Solomon][Reed-Solomon Error Correction]]
**** TODO [[http://en.wikipedia.org/wiki/Reservoir_sampling#cite_note-1][Resevoir Sampling]]
**** TODO [[http://en.wikipedia.org/wiki/Selection_algorithm#Linear_general_selection_algorithm_-_Median_of_Medians_algorithm][Selection Algorithm]]
**** TODO [[http://en.wikipedia.org/wiki/Simplex_algorithm][Simplex Algorithm]]
**** TODO [[http://en.wikipedia.org/wiki/Stable_marriage_problem][Stable Marriage Problem]]
**** TODO [[http://en.wikipedia.org/wiki/Strassen_algorithm][Strassen Algorithm]]
**** TODO [[http://link.springer.com/book/10.1007/978-3-642-15328-0/page/1][Algorithms Unplugged (Book)]]
**** TODO [[http://www.cs.bell-labs.com/cm/cs/pearls/][Programming Pearls (a source of algorithms)]]
**** TODO [[http://www.cs.bell-labs.com/cm/cs/pearls/maxsum.c][Maximum Sum Subsequence]]
**** TODO [[http://www.cs.utexas.edu/~moore/best-ideas/mjrty/][Linear Time Majority Vote]]
**** TODO [[http://www.hutter1.net/ai/pfastprg.htm][Fastest and Shortest Algorithm for all well-defined problems]]
**** TODO [[Khttp://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm][Knuth-Morris-Pratt (KMP)]]

** Artificial intelligence

*** Reinforcement Learning

**** Terms

- reward :: what the agent expects to receive in the short term for
            taking a particular action.  May be negative (punishment)
            or positive (actual reward).

- value :: what the agent expects to receive in the long term by
           executing its policy.

*** Neural Networks

*** Bayesian Networks

*** Books

**** "Artificial Intelligence, A Modern Approach" by Norvig, et al.

*** Key Challenge of Artificial Intelligence

To find out how to write programs that, to the extent possible,
produce rational behavior from a small amount of code rather than a
large number of table entries.

*** Agent Types

These agents types are defined in the terms section

**** Simple Reflex Agent

Pseudocode: [[./SimpleReflexAgent.hs][Source Code]]

**** Model Based Reflex Agent

Pseudocode: [[./ModelBasedAgent.hs][Source Code]]

**** Goal-Based Agent

Pseudocode: [[./GoalBasedAgent.hs][Source Code]]

**** Utility Based Agent

Pseudocode: [[./UtilityBasedAgent.hs][Source Code]]

*** Learning Agent

See Figure 2.15 on page 53

A learning agent has four conceptual components (defined further in terms section):

- Learning Element

- Critic

- Problem Generator

- Performance Element

*** Task Environment 

**** Fully Observable or Partially Observable

If the agent can observe everything there is to know about the
environment at all times, then the environment is fully observable,
otherwise it's partially observable.

**** Deterministic or Stochastic

If the next state of the environment is completely defined by the
current state of the environment and the next action of the agent,
then it is a deterministic environment.  See: strategic.

**** Episodic or Sequential

An environment is episodic when the agent acquires a percept, then
takes a single action based on the updated percept sequence.  This
process then repeats.  Importantly the next episode does not depend on
the actions taken during any previous episode.  Sounds like a Markov
Chain.  An example is detecting defects in a product on an assembly
line.

In a sequential environment the current decision can affect all future
decisions.  Some examples would be chess and taxi driving.

**** Static or Dynamic

If the environment can change while the agent is thinking then the
environment is dynamic.  If the environment is dynamic and it's
changing faster than the agent can decide what to do, the agent does
nothing.

If, in a static environment, the only thing that changes is the
agent's performance measure the environment is semidynamic.

**** Discrete or Continuous

Discreteness can be applied to several aspects of the task environment.

- Time - whether time passes in a continuous nature or not

- Percepts - the percepts the agent collects may be discrete or
  continuous.

- Actions - the actions that the agent takes may be discrete or
  continuous

- States - whether or not there are a finite number of states.

**** Single Agent or Multi Agent

Multiagent environments can be cooperative or competitive.

*** Terms
 
- agent :: something that perceives its environment using one or more
           sensors and acts upon its environment using one or more
           actuators.  An agent is a combination of the agent
           architecture and an agent program.

- agent architecture :: computing device with physical sensors and
     actuators.

- agent function :: a function that maps different percept sequences
                    to actions.  The agent function is computed at
                    three distinct times: when it is being designed,
                    when an action is being deliberated, and when the
                    agent learns, the agent function computes how to
                    modify the agent's behavior.

- agent program :: software that implements the agent function mapping
                   percepts into actions.

- actuator :: a way in which the agent interacts with its environment
              (e.g. robotic hands, computer display, etc.)

- critic :: a component of a learning agent that provides input on how
            well the agent is doing based on a fixed performance
            standard and determines how the performance element should
            be modified to do better in the future.  The standard used
            for critiquing actions must be fixed (i.e. the agent
            should not modify its critic to influence its behavior).

- condition-action rule :: A rule that states when a specific
     condition becomes true, a specific action should be taken.

- exploration :: an example of information gathering, often done to
                 gain information about an unfamiliar environment.

- goal-based agent :: an agent that has information about the goal it
     should acheive and is programmed to analyze the goal, and its
     model of the environment (if it's available) in order to select
     actions.  Sometimes goal-based action selection is easy (when the
     goal can be acheived in a single action).  Sometimes goal-based
     action selection is more tricky.  In these cases planning and
     search techniques can be used.  Goal-based agents are more
     flexible than agents that follow condition-action rules because
     the knowledge that supports its decisions is represented
     explicitly and can be updated.

- information gathering :: actions taken to modify futur percepts,
     often done by rational agents to increase their expected
     performance.

- learning element :: a component of a learning agent that is
     responsible for making improvements

- model :: information on how the world evolves independently of the
           agent's actions and how the agent's actions affect the
           world.  Combined these two information sets states "How the
           World Works" according to the agent.

- model-based reflex agent :: this agent keeps track of what it has
     observed in some internal state.  Updating this internal state
     requires two kinds of knowledge: 1) how the world evolves
     independently of the agent and 2) how the agent's actions affect
     the world.  Giving a simple reflex agent the ability to maintain
     and update state is the most effective way of handling partial
     observability.

- percept :: an agent's perceptual inputs at a given point in time.

- percept sequence :: the complete history of the agents observations
     (percepts).

- performance element :: a component of a learning agent that is
     responsible for selecting external actions.  The perforance
     element is what we have previously thought of as the whole agent.
     It's as if a learning agent is a regular agent along with some
     additional elements.  It takes percepts and decides actions.

- performance measure :: embodies the success criteria for the success
     of the agent.  It is better to derive the performance measures
     from what you actually want and not how you want the agent to
     behave.

- problem generator :: a component of a learning agent that suggests
     actions that will lead to new and informative experiences.  Helps
     the agent explore and avoid a potentially sub-optimal, greedy
     solution.

- rational agent :: an agent that always does the right thing Ivery
                    entry in the agent's table contains an action that
                    maximizes the agent' success.  A rational agent is
                    not a perfect agent.  Rationality maximizes
                    expected performance not actual performance.

- sensor :: A senor collects data, measurements, stimulus from the
            agent's environment.

- simple reflex agent :: an agent that selects its next action based
     entirely on the current percept, ignoring all previous percepts.
     These agents are simple but they are of limited intelligence.
     Even a little bit of limited observability can cause the simple
     reflex agent a lot of problems because they may ignore crucial
     information.  They are subject to infinte loops (oscilating
     between two states) but these loops can be broken out of by
     adding some randomness to the agent's agent function.

- strategic :: where the next state of the environment deterministic
               except for the actions of other agents.

- task environment :: the problem to which the agent is the solution.
     It is comprised of PEAS (Performance Measure, Environment,
     Actuators, and Sensors).

- utility-based agent :: An agent that uses a utility function to
     select its actions.  Goals alone are insufficient to produce
     high-quality behavior in most environments.  Goals can be in
     conflict.

- utility function :: A function maps a state (or sequence of states)
     to a number.  A utility function can help address the problem of
     conflicting goals (speed vs. safety).  When their are multiple
     goals, the agent can use the utility function to weigh expected
     performance of acheiving the goal against the likelihood of
     acheiving each goal.

*** Source Code

- [[./Agent.hs][Agent.hs]]

** Big Data

*** Hadoop

*** Cascading

** Cognitive Science

*** Books

**** "Brain Rules" by John Medina


**** "Now you See It" by Cathy Davidson

[[http://www.amazon.com/Now-You-See-Attention-Transform/dp/0670022829][On Amazon]]

** Computer Architecture

*** Links [1/1]

- [X] [[https://en.wikipedia.org/wiki/Flynn%2527s_taxonomy][Flynn's Taxonomy]] - a classification of computer architectures
  (e.g. Single Instruction, Single Data Stream (SISD)).  I get the
  impression that all of the modern Intel chips (i3, i5, i7) and
  perhaps some previous models are MIMD.

*** Memory Hierarchy

**** Terms

- stall :: when a CPU must wait for a cache line to be filled from
           main memory.

**** References:

- [[http://en.wikipedia.org/wiki/CPU_cache#Multi-core_chips][CPU Cache (Wikipedia)]]

**** Components

***** Registers

Intel 64 bit Architectures have 16 general purpose registers when in
64 bit mode.  [[http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-1-manual.pdf][Source]]

***** L1 Cache 

Typically 1 L1 cache per core

***** L2 Cache 

Typically shared by two cores

***** L3 Cache 

Typically shared across all cores

***** Main Memory

***** Disk

***** Network

**** Concepts

***** Cache Line

Typically 64 bytes

***** NUMA
***** MESI Protocol
***** Interconnect
***** Load/Store Buffers
***** Write Absorbtion

**** Times for Common Operations

Sources: [[http://surana.wordpress.com/2009/01/01/numbers-everyone-should-know/][Surana]], [[https://docs.google.com/viewer?url%3Dhttp%253A%252F%252Fsoftware.intel.com%252Fsites%252Fproducts%252Fcollateral%252Fhpc%252Fvtune%252Fperformance_analysis_guide.pdf][Intel]], [[http://norvig.com/21-days.html#answers][Peter Norvig]]

|-------------------------------------+------------------------+------------------+--------|
| Operation                           | Time (nanoseconds) <r> |   Alternate Unit | Cycles |
|-------------------------------------+------------------------+------------------+--------|
| <l>                                 |                    <r> |              <r> |    <r> |
| L1 cache reference                  |                 0.5 ns |                  |     ~4 |
| Exeute Instruction                  |                   1 ns |                  |        |
| Branch mispredict                   |                   5 ns |                  |        |
| L2 cache reference                  |                   7 ns |                  |    ~10 |
| Mutex lock/unlock                   |              25-100 ns |                  |        |
| Main memory reference               |                 100 ns |                  |        |
| Compress 1K bytes with Zippy        |              10,000 ns |  10 microseconds |        |
| Send 2K bytes over 1 Gbps network   |              20,000 ns |  20 microseconds |        |
| Read 1 MB sequentially from memory  |             250,000 ns | 250 microseconds |        |
| Round trip within same datacenter   |             500,000 ns | 500 microseconds |        |
| Fetch from new disk location (seek) |           8,000,000 ns |          8 msecs |        |
| Read 1 MB sequentially from network |          10,000,000 ns |         10 msecs |        |
| Read 1 MB sequentially from disk    |          20,000,000 ns |         20 msecs |        |
| Send packet CA->Netherlands->CA     |         150,000,000 ns |        150 msecs |        |
|-------------------------------------+------------------------+------------------+--------|

Other Metrics Of Interest

|------------------------------------------+----------------------|
| Metric                                   |                Value |
|------------------------------------------+----------------------|
| <l>                                      |                  <r> |
| Speed of Light                           | 186,000 miles/second |
| Circumference of Earth                   |         40,000 miles |
| Maximum Transmission Distance (on Earth) |         20,000 miles |
| Width of United States                   |          2,770 miles |
|------------------------------------------+----------------------|


*** Central Processing Unit


*** Networking


*** CUDA


*** Storage Drives

**** SSD

**** Hard Drive (Rotating)

** Databases

*** Relational

**** MySQL

**** PostgreSQL

*** NoSQL

**** Cassandra

***** Drivers

****** Java

******* [[https://github.com/datastax/java-driver][Official DataStax CQL Driver]]

- [[http://www.datastax.com/documentation/developer/java-driver/1.0/webhelp/index.html][Documentation]]
- [[http://www.datastax.com/drivers/java/apidocs/][API]]

**** MongoDB

** Data Structures

*** Analysis

**** Big O

**** Analytic Combinatorics

** Distributed Computing

*** Books 


**** [[http://www.amazon.com/Elements-Distributed-Computing-Vijay-Garg/dp/0471036005]["Elements of Distributed Computing"]] by Vijay K. Garg

***** Benefits of Distributed Systems

- Scalability - Processors can be added and removed easily.

- Modularity and Heterogeneity - The system can be comprised of
  systems with different processors.

- Data Sharing - Multiple organizations can share data.  Multiple
  office locations or data centers too.

- Resource Sharing - An expensive processor can be shared by multiple
  organizations.

- Geographical Structure - 

- Reliability - Failure of one system does not affect the availability
  of the others.

- Low Cost - It's cheaper to buy a lot of commodity computers and
  connect them via a high speed network than to buy high performance
  computers.

Don't abandon single computer parallelism.  It still has benefits
(performance mostly).

***** Defining Characteristics of a Distributed System

- No shared clock - causality can help tackle this problem

- No shared memory - it is difficult to observe any global property of
  the system.

- No accurate failure detection - it is impossible to differentiate
  between a slow processor and a failed processor.

***** Notation

: (op free-var-list : range-of-free-vars : expression)

For example:

(\forall i : 0 \le i \le 10 : i\sup2 \le 100) 

where:

- op is a universal or existential quantifier
- free-var-list is the list of variables over which the quantification is made
- range-of-free-vars is the range of the free variables


***** Model of a Distributed System

- Set of N processes without a shared clock and without shared memory
- A pair of processes can be connected by unidirectional channel along
  which messages flow
- The processes and communication links form a directed graph
- If a pair of processes send messages back and forth between each
  other, then that is modeled as two channels, one for each direction
  the messages are passed in.
- Channels are assumed to (neither of which are true):
 - have infinite buffer
 - be error free
- A message may be delayed on the channel for arbitrary but finite
  amounts of time.
- The state of the channel is all of the messages sent on the channel
  that have not been received.
- Processes are modeled as state machines (that transition between
  states in response to events).
- When a process receives an event, the state of at most one channel
  may also change (e.g. another message added to that channel).  This
  implies that as a result of a state change, a process can only
  notify one other process.

***** Interleaving Model

- In this model a run of the system is a global sequence of events.
  The ordering of events is total.
- The global state of such a system is the cross product of all
  process states and all channel states.
- An initial state is one in which all the channels are empty and all
  the processes are in an initial state (taken from a subset of all of
  the process' states).

***** Happened Before Model

Leslie Lamport argued that at best you could discuss a system's
partial ordering of events.

A run in the Happened Before model is a tuple: (E, H) where E is the
set of all the events that took place and H is the partial order of
the events in E.

***** Potential Causality Model

Within a single process, not every event causes another event but
there is a partial ordering of causes and effects within a single
process.

Potential Causality is cheaper to compute than Causality so we'll use
Potential Causality.

Two events are independent if neither one potentially caused the
other.


*** Links [0%]

- [ ] [[https://en.wikipedia.org/wiki/CAP_theorem][CAP Theorem]]
- [ ] [[https://en.wikipedia.org/wiki/Edsger_W._Dijkstra_Prize_in_Distributed_Computing][Dijkstra Prize in Distributed Computing]]
- [ ] [[https://en.wikipedia.org/wiki/Gossip_protocol][Gossip Protocol (Wikipedia)]]
- [ ] [[https://en.wikipedia.org/wiki/Paxos_algorithm][Paxos (Wikipedia)]]
- [ ] [[https://en.wikipedia.org/wiki/Category:Distributed_computing][Wiki Category]]

*** Akka

Has its own section under [[Scala]].

*** Consensus


*** Projects

**** Akka

**** Cassandra

**** JGroups

**** Kafka

**** MongoDB

**** RabbitMQ

**** Storm

***** Links [0/3]

- [ ] [[https://github.com/nathanmarz/storm/blob/master/storm-core/src/clj/backtype/storm/daemon/nimbus.clj][Nimbus Source Code (Clojure)]]
- [ ] [[https://github.com/nathanmarz/storm/wiki/Concepts][Storm Concepts]]
- [ ] [[https://github.com/nathanmarz/storm/wiki/Tutorial][Tutorial]]

***** Concepts

****** IBasicBolt vs. IRichBolt

- IBasicBolt :: All acking is managed for you. Throw a FailedException
                if you want to fail the tuple.

- IRichBolt :: Implementors must ack or fail the tuple themselves in
               the execute call.

****** Cluster State

Nimbus and the Supervisor daemons are fail-fast and stateless.  All
cluster state is stored by Zookeeper on disk.  You can kill -9 Nimbus
and the Supervisors and they'll restart correctly.

- Nimbus :: The master node.  All other nodes in the cluster are
            Worker nodes

- Stream :: An unbounded sequence of Tuples; the primary abstraction
            in Storm.

- Supervisor :: A daemon that runs on every Worker Node.  It listens
                for work assignments and starts and stops worker
                processes.

- Worker Node :: A Node in a Storm Cluster that runs Spouts and/or
                 Bolts.  Every worker node runs a daemon called the
                 Supervisor.

- Zookeeper :: Responsible for all communication between Nimbus and
               the Supervisors.


**** Zookeeper


*** Terms

- Byzantine Failure :: a failure mode in which systems don't crash but
     continue running and producing invalid requests and data.

- Byzantine Fault Tolerance :: a means of fault tolerance that guards
     against Byzantine failures.

- Concurrent :: In the Happened Before Model two events e and f are
                concurrent if e did not happen before f and f did not
                happen before e.  Does that really mean that the two
                events happened at the same time or does that just
                mean that you can't establish a relative ordering of
                the two events?
- Distributed System :: A computer system composed of multiple
     processors connected by a network.  Processors communicate by
     sending messages over the network.

- Happened Before :: If event e locally or remotely immediately
     precedes event f, then event e happened before event f.  This
     relationship is transitive.

- Locally Precedes :: In the Happened Before model an event e locally
     immediately precedes an event f, if event e happened immediately
     before f in the process' sequence of events.

- Remotely Precedes :: In the Happened Before model, an event e
     remotely precedes an event f iff e is the send event for a
     message and f is the receive event for that same message.


*** Two Generals Problem

See: [[http://en.wikipedia.org/wiki/Two_Generals%2527_Problem][Wikipedia]]

A thought experiment used to highlight the challenges coordinationg an
action by communicating over an unreliable link.

There are three valleys.  The center valley has a city in it.  The
left and right valleys have armies encamped in them.  Both armies must
attack the city in order for the attack to succeed.  If one army sends
a messenger to tell the other army when the attack will occur, it is
possible that the messenger will be captured.  Knowing about the
potential for capture, the army that sent the message may hesitate when
it comes time to attack.

*** Vector Clocks

** Denotational Semantics

*** People

**** Conal Elliot

[[http://conal.net/][Home Page]]

** Emacs
*** Elisp
*** Packages
**** Org-Mode
***** LaTeX
****** Examples

- Summation - \sum x
- \exist x \rarr x = 0
- \forall x \rarr x \gt x
- 4 \div 2 =div  =  2
- \pi

****** Arrows

\Leftarrow (Leftarrow)      
\Leftrightarrow (Leftrightarrow)                                      
\Rightarrow (Rightarrow)          
\downarrow (downarrow)                                                                                                      
\hArr (hArr)                                                                                      
\harr (harr)                                                                                                                
\lArr (lArr)                
\uparrow (uparrow)        
\larr (larr)                      
\leftarrow (leftarrow)            
\leftrightarrow (leftrightarrow)    
\rArr (rArr)                
\rarr (rarr)                      
\rightarrow (rightarrow)                                      

****** Uncategorized 

\amp (amp)                                            
\approx (approx)                                                      
\because (because)                                                                                
\bullet (bullet)            
\cap (cap)                                                            
\cdots (cdots)                                                                                    
\circ (circ)                        
\colon (colon)              
\cong (cong)                                                          
\cup (cup)                          
\deg (deg)                          
\div (div)                  
\dots (dots)                                                          
\emptyset (emptyset)              
\equal (equal)                    
\equiv (equiv)                      
\exists (exists)            
\exp (exp)                        
\fnof (fnof)                        
\forall (forall)          
\frac12 (frac12)            
\frac14 (frac14)                  
\frac34 (frac34)                    
\frown (frown)              
\geq (geq)                  
\gets (gets)                                                          
\gt (gt)                  
\hellip (hellip)          
\in (in)                    
\infty (infty)            
\int (int)                                                                                        
\isin (isin)                                          
\lambda (lambda)                  
\land (land)                        
\lang (lang)              
\laquo (laquo)              
\le (le)                    
\leq (leq)                                            
\lg (lg)                                                                                                                    
\ln (ln)                  
\log (log)                                                                                        
\lor (lor)                                            
\lrm (lrm)                          
\lsquo (lsquo)              
\lt (lt)                          
\max (max)                                            
\micro (micro)                      
\middot (middot)          
\minus (minus)                    
\ne (ne)                            
\neg (neg)                
\neq (neq)                  
\ni (ni)                  
\not (not)                  
\notin (notin)                    
\nsub (nsub)                        
\nsup (nsup)                                                                                                                
\oplus (oplus)                      
\otimes (otimes)                                      
\partial (partial)                  
\perp (perp)              
\pi (pi)                                                              
\plus (plus)                
\plusmn (plusmn)                  
\prec (prec)                
\preccurlyeq (preccurlyeq)        
\preceq (preceq)                    
\prime (prime)            
\prod (prod)                
\radic (radic)                                                        
\rang (rang)              
\raquo (raquo)              
\real (real)                                                  
\rsaquo (rsaquo)                    
\rsquo (rsquo)                                                                                                              
\sdot (sdot)                                          
\setminus (setminus)                
\sim (sim)                          
\simeq (simeq)            
\sin (sin)                  
\sinh (sinh)                      
\slash (slash)                      
\sub (sub)                  
\sube (sube)                      
\subset (subset)                    
\succ (succ)              
\succcurlyeq (succcurlyeq)  
\succeq (succeq)                  
\sum (sum)                          
\sup (sup)                
\sup1 (sup1)                
\sup2 (sup2)                      
\sup3 (sup3)                        
\supe (supe)              
\supset (supset)                                              
\tan (tan)                          
\therefore (therefore)                                                                            
\theta (theta)                                                                                                              
\tilde (tilde)            
\times (times)              
\to (to)                          
\triangleq (triangleq)    
\varepsilon (varepsilon)                                                                                                    

**** Magit
**** Haskell-Mode
**** Yasnippet
**** ido
*** Tips & Tricks

** Emotionally Focused Therapy

*** Links 

- [[https://en.wikipedia.org/wiki/Emotionally_focused_therapy][on Wikipedia]]

** Evolutionary Computing

*** General Notes

There are two natural ways of solving problems: using the brain (which
leads to the field of neurocomputing) and evolution (which leads to
the field of evolutionary computing).

An Evolutionary Algorithm has three components:

- Model :: a way of transforming inputs into outputs

- Input :: inputs into the problem

- Output :: the result of feeding the input into the model

Typically in EA one of these is unknown.  For each possible unknown
there is a kind of Evolutionary Algorithm that results:

- Optimization :: You are trying to find an input that when fed to the
                  model produces some optimal output.  By evolving the
                  inputs and evaluating them using the model, an
                  optimal input can be found.

- Modeling (System Identification) :: The inputs are known, and the
     outputs are known, but the formulas for mapping inputs to outputs
     (i.e. the model) is unknown.  An example would be stock market
     analysis.  We have historical data on stock prices and market
     conditions (the inputs) and we see how the market reacted in
     response to that historical data (the outputs) but we're not sure
     of the dependency between the two (the model, for example how
     traders react to different inputs).  By variation and selection
     we can find a model that optimally reconciles the inputs and the
     outputs.

- Simulation :: The output is unknown.  Find out what this means and
                revisit it.

*** Components of an Evolutionary Algorithm

- representation :: 
- evaluation function (fitness function) ::
- population ::
- parent selection mechanism ::
- variation operators ::
- survivor selection mechanism (replacement) ::

*** Terms

- adaptive surface (or adaptive landscape) :: The n-dimensional space
     where n - 1 of those dimensions represent traits that define a
     solution and 1 of those dimensions represents some fitness that
     EC is trying to maximize.

- crossover :: when genes from two genotypes are combined to create
               offspring that takes genetic material from both parent
               genotypes.  For each potential gene a random parent is
               selected to provide that gene.

- environment :: the problem to solve

- genotype :: an internal representation or encoding of the phenotype

- global optimum :: The optimal solution

- local optimum :: A solution that is better than, or equal to all of
                   its neighbors but is not the optimal solution.

- multimodal problem :: A problem that has multiple points that are
     better than their neighbors thus it is possible to get stuck on a
     local optimum.

- mutation ::

- phenotype :: a possible solution to the problem to solve.

- selection :: determining which genotypes should have the chance to
               crossover and produce offspring.

- unimodal problem :: A problem with only a single maximum where all
     other points on the adaptive surface are either level or climbing
     up to the single (and therefore global) optimum.  a

- variance :: a way of introducing new genotypes into the population.
              See mutation and crossover.
** Fault Tolerance

*** Terms

- failure :: When the delivered service no longer complies with the
             specification.  If there is no specification, there can
             be no failure. Failures are observed by the user of the
             system.  Failures are caused by errors.

- error :: An incorrect system behavior that may cause a
           failure. Errors fall into two categories: timing and value.
           Value errors can take the form of incorrect state or an
           incorrect discrete value. Errors can be detected before
           they cause failures.  Errors are the manifestation of
           faults.  The presence of errors implies the presence of
           faults.

- fault :: a defect in a system that can cause an error.  Faults can
           be caused by incorrect requirements, coding defects,
           incorrect designs, etc.  A fault that is not causing any
           errors is latent.

- latent :: A fault that is not causing any errors is latent.

- active :: A fault that causes an error is active.

- fail-silent :: a system that presents the correct result or no
                 result at all.

- crash-failure :: the system stops after it detects an error


*** Bad Assumptions

- Only one error occurs at a time - multiple errors can occur at the
  same time.  In a large enough system, it's almost a guarantee that
  multiple errors will happen at the same time.

- One error is recovered from the next one occurs - recovery from one
  error can overlap the activation of another fault.

- Each error is independent from each other error - errors can cascade


*** Fault -> Error -> Failure

*** Books [0/1]

- [ ] [[http://techbus.safaribooksonline.com/book/software-engineering-and-development/patterns/9780470319796][Patterns for Fault Tolerant Software]] by Robert S. Hanmer

** Functional Programming 

*** Lambda Calculus


*** Functional Data Structures


*** Functional Reactive Programming

** Information Theory
   
*** Entropy

*** Compression

** Learning

** Machine Learning

*** Links

- [ ] [[http://www.kaggle.com/][Kaggle]]


*** Supervised Learning


**** Decision Trees

**** Naive Bayesian Classifier


*** Unsupervised Learning


**** Clustering


*** Ensemble Methods


*** Boosting


*** Tools

**** Weka

***** Links
 
- [[http://www.cs.waikato.ac.nz/ml/weka/][Home Page]]

** Mathematics
*** Algebra

*** Linear Algebra

*** Discrete Math
**** Books
***** "Concrete Mathematics" by Donald Knuth, et al.

*** Euler's Constant

*** Causality
**** Books
***** "Causality" by Judea Pearl

*** Abstract Algebra

*** Probability

*** Statistics

*** Distance Metrics

*** Graph Theory

*** Proofs

** Operating Systems
*** Concepts
**** Virtual Memory
**** Devices
**** Networking
**** Security
**** Troubleshooting
**** Optimizing
*** Linux

*** FreeBSD
    
** Programming Environments

*** Java Virtual Machine

*** .NET Runtime

I'm pretty much focusing on the JVM for now.


** Programming Languages

*** Java
    
**** Features

***** NIO
      
***** Lambdas

***** Concurrency


**** Tools

***** Maven

****** Build Life Cycle

- default :: handles project deployment

- clean :: handles cleaning of your project

- site :: handles creation of your project's site documentation

****** Phases of the default lifecycle

- validate :: validate the project is correct and all necessary
              information is available

- compile :: compile the source code of the project

- test :: test the compiled source code using a suitable unit testing
          framework. These tests /should not require the code be
          packaged/ or deployed

- package :: take the compiled code and package it in its
             distributable format, such as a JAR.

- integration-test :: process and deploy the package if necessary into
     an environment where integration tests can be run

- verify :: run any checks to verify the package is valid and meets
            quality criteria

- install :: install the package into the local repository, for use as
             a dependency in other projects locally

- deploy :: done in an integration or release environment, copies the
            final package to the remote repository for sharing with
            other developers and projects.

****** Links

- [[https://maven.apache.org/guides/index.html][Documentation]]


***** JavaDoc

Multiline Code Samples

: * <pre>
: * {@code
: * Set<String> s;
: * System.out.println(s);
: * }
: * </pre>


*** Scala
    
**** Links

- [[http://docs.scala-lang.org/][Home Page]]
- [[http://www.scala-lang.org/api/current/#package][ScalaDocs (Current)]]
- [[http://twitter.github.io/effectivescala/][Effective Scala]]


**** Macros


**** Akka

***** Links 

- [[http://akka.io][Home Page]]

- [[http://doc.akka.io/docs/akka/2.2.1/scala.html][Scala Documentation]]

- [[http://doc.akka.io/api/akka/2.2.1/][ScalaDocs]]
  
***** Concepts

- Actor :: Every actor has one supervisor which is the actor that
           created it. ([[http://doc.akka.io/docs/akka/2.2.1/general/actor-systems.html][Source]]) What about the top level actor?  It
           either has no supervisor or it wasn't created by an actor.
           In akka an actor is about 300 bytes.

- Actor Path :: a hierarchical name that refers to actors anchored by
                an ActorSystem.  Local paths start with "akka://".
                Remote paths start with something like
                "akka.tcp://system@host:port".  "akka.udp" is also
                available.

- Actor System :: a hierarchical group of actors which share common
                  configuration.  It is also used for looking up
                  actors.  They are heavyweight so create one per
                  logical application.

- Ask :: The '?' operator initiates an ask operation.  Ask waits for a
         response and as such incurs greater overhead.

- Consumer :: 

- Divide and Conquer :: Tasks are split up and delegated to the point
     that they are of a manageable size.

- Error Kernel :: [[http://www.erlang.se/doc/programming_rules.shtml#HDR15][Source]] The part of the system that must be correct.
                  All other parts can be incorrect and should be
                  restarted when the incorrectness is identified.

- Failure :: If an actor cannot respond to a message, it bubbles the
             error up to its supervisor.

- FSM :: A trait that allows an Actor to behave like a finite state
         machine.

- Message Delivery Guarantees :: Akka makes two guarantees: 1)
     at-most-once delivery (i.e. no guaranteed delivery) and 2)
     message ordering per sender–receiver pair ([[http://doc.akka.io/docs/akka/2.2.1/general/message-delivery-guarantees.html#message-delivery-guarantees][Source]]).

- Remote Creation :: when akka creats an actor on a remote node

- Remote Lookup :: when akka looks up an actor on a remote node.

- Remoting Use Cases :: The two ways that remoting can be used.  See
     Remote Lookup and Remote Creation

- Scheduler :: If you need to make sure that something happens in the
               future, use the ActorSystem Scheduler.

- Tell :: Sending a fire-and-forget message to another actor.  The
          sending actor's reference is implicitly sent along with the
          message.  The '!' operator initiates a tell operation.  Tell
          is more performant and scalable because there is no need to
          wait for a response (using a Future).  Compare with Ask.
	  
***** Supervision Guidelines

[[http://doc.akka.io/docs/akka/2.2.1/general/actor-systems.html][Source]]

- If an actor sends sub tasks to another actor, the sending actor
  should supervise the other actor.

- If an actor maintains some important state, it should source out any
  dangerous tasks to other actors so that that it can be alerted to
  failures without dying itself (and losing the data).

- If one actor depends on another for carrying out its duty, it should
  watch that actor and respond to its termination.  Watching is not
  the same as supervision.

***** Actor Best Practices

****** References

- [[http://doc.akka.io/docs/akka/2.2.1/general/actor-systems.html][Akka Actor System Documentation]]
- [[http://doc.akka.io/docs/akka/snapshot/scala/actors.html][Akka Actor Documentation]]
       
****** Immutable Messages

Use case classes when possible.

****** Give each Actor Class a Companion Object

Example:

: object DemoActor {
:   def props(name: String): Props = Props(classOf[DemoActor], name)
: }
:  
: class DemoActor(name: String) extends Actor {
:   def receive = {
:    :
:   }
: }

****** Never block

Actors should not block.  While the actor is blocked, it cannot
process any messages.  Blocking can lead to deadlock.

But if an actor must block consider doing so from within a set of
actors managed by a router.

****** Don't send behavior (e.g. closures) in messages

They don't remote well.

****** Error Kernel 

Top-level actors are the innermost part of your error kernel so create
them sparingly and hierarchically.

If sounds like actors that know things are more important to keep
alive than actors that do things.  The actor that does something can
be recreated at a minimal cost.  The actor that knows something loses
all that information if it is lost.  Some similarities to human
organizations...  Do the best actor hierarchies strive to separate
know-ers from do-ers?  Some know-ers can easily recreate their
knowledge so maybe these know-ers are more replaceable than other
know-ers.  In that case, there is a spectrum of agent preservation
ranging from the lowest degree (let it crash and then replace it) all
the way up to the highest degree (keep it away from anything that can
fail).

****** Actor State

I've been looking for some recommended way of handling actor state
(e.g. if an actor needs to keep track of some data).  My previous
experience with actor state is from the Erlang world, where either OTP
handles updating your state or you manually call your actor's loop
function with the adjusted state.  The closest thing I have found is
an [[https://github.com/akka/akka/blob/master/akka-samples/akka-sample-persistence/src/main/scala/sample/persistence/ConversationRecoveryExample.scala][example]] bundled with Akka that shows a mutable Int (var) used as a
counter.  The cluster [[https://github.com/akka/akka/blob/master/akka-samples/akka-sample-cluster/src/main/scala/sample/cluster/stats/StatsSample.scala#L78][example]] also maintains a cache (as a var holding
an immutable Map) in an actor.

****** Consider Using Become to Change Behavior

When your actor needs to change the way it responds to messages and
you don't want to use the FSM capabilities of Akka, consider the
become method.

****** Actor System and Ports

Each actor system running on a server needs a different port even if
the names of the actor systems are different.  This is because each
Actor system maintains its own port.

***** Remoting

Resources [/]

- [[http://doc.akka.io/docs/akka/2.2.1/scala/remoting.html][Akka Docs on Remoting]]
- [[http://doc.akka.io/docs/akka/2.2.1/scala/remoting.html#remote-configuration-scala][Remote Configuration]]


**** scalaz
     

*** Haskell

**** Links

- [[http://www.haskell.org/haskellwiki/Haskell][Haskell Home Page]]
- [[http://book.realworldhaskell.org/read/][Real World Haskell]]
- [[http://learnyouahaskell.com/chapters][Learn You a Haskell]]
- [[http://www.haskell.org/ghc/docs/latest/html/libraries/index.html][Libraries Documentation]]
- [[http://themonadreader.wordpress.com/][The Monad.Reader]]
- [[http://planet.haskell.org/][Planet Haskell]]

**** To Read [0%] [0/14]

- [ ] [[./yaht.pdf][Yet Another Haskell Tutorial]]
- [ ] [[./HR.pdf][Haskell Road to Logic Math and Programming]]
- [ ] [[http://en.wikibooks.org/wiki/Haskell][Haskell Wiki Book]] ([[./HaskellWikibook.pdf][PDF]])
- [ ] [[http://www.haskell.org/haskellwiki/Hitchhikers_guide_to_Haskell][Hitchhiker's Guide to Haskell]]
- [ ] [[./awkward-squad.pdf][Tackling the Awkward Squad]]
- [ ] [[http://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours][Write Yourself a Scheme in 48 Hours]]
- [ ] [[http://www.haskell.org/haskellwiki/Scrap_your_boilerplate][Scrap Your Boilerplate]]
- [ ] [[./HPR.pdf][Higher-order + Polymorphic = Reuse]]
- [ ] [[./whyfp.pdf][Why Functional Programming]]
- [ ] [[./monads2arrows.pdf][Generalizing Monads to Arrows]]
- [ ] [[./arrows_robots.pdf][Arrows, Robots, and FRP]]
- [ ] [[./edsl.pdf][Building Domain-Specific Embedded Languages]]
- [ ] [[./monad_interpreter.pdf][Build a Monadic Interpreter]]
- [ ] [[http://www.haskell.org/haskellwiki/Category:Style][Haskell Style Wiki Category]]
- [ ] [[http://www.haskell.org/haskellwiki/Emacs][Emacs & Haskell]]
- [ ] [[http://www.haskell.org/haskellwiki/How_to_write_a_Haskell_program][How to Write a Haskell Program]]
- [ ] [[http://www.haskell.org/ghc/docs/latest/html/users_guide/index.html][GHC/GHCI Manual]]
- [ ] [[http://www.haskell.org/haskellwiki/Research_papers/Functional_pearls][Functional Pearls]]
- [ ] [[http://www.haskell.org/haskellwiki/Research_papers/Data_structures][Research Papers on Data Structures]]
- [ ] [[http://www.haskell.org/haskellwiki/Research_papers/Top_10][Top Research Papers]]
- [ ] [[http://www.scs.stanford.edu/11au-cs240h/notes/][Lecture Notes from Stanford's Haskell Course]]
  
**** Concurrency

***** CUDA

**** Arrows

**** Monoids

**** MonadPlus

**** Lenses


*** C++
    
**** Lambda Expressions


**** Concurrency
     

**** Concepts (next version of C++?)


**** Templates


**** C++ Renaissance


*** Python

**** Idioms

**** Pandas

**** IPython

**** SciKit-Learn
     
**** Generators
**** The with keyword


*** Other
**** Prolog
***** Difference Lists
***** Natural Language Processing
**** ML
***** Side-Effects
**** Javascript
     
** Software Architecture

*** Hexagonal Architecture

** Testing

*** Test Driven Development

**** Hamcrest

Anagram for matchers

**** EasyMock

***** Links

- [[http://www.easymock.org/EasyMock3_1_Documentation.html][Documentation]]

- [[http://www.easymock.org/api/easymock/3.1/index.html][JavaDocs]] ([[http://www.easymock.org/api/easymock/3.1/index.html][expect]])

***** Expect

Some commonly used expectations:

- andReturn(T value) 
- andThrow(Throwable throwable) 
- anyTimes() 
- atLeastOnce() 
- once() 
- times(int count) 


*** Behavior Driven Development

** Ultra Learning

*** Links [66%] [2/3]

**** TODO [[./scott_young.pdf][Scott's Book on Learning]]

**** DONE [[http://www.scotthyoung.com/blog/2011/09/01/learn-faster/][The Feynman Technique]]

**** DONE [[http://calnewport.com/blog/2012/10/26/mastering-linear-algebra-in-10-days-astounding-experiments-in-ultra-learning/][Interview with Scott Young]]

The method you use to learn matters lot.  Deeper levels of processing
can double your efficiency.

Cramming does not work at MIT; courses build on each other.

Deepening Understanding is made up of two things:

- Making Connections - connections provide context
- Debugging Errors - make sure your understanding of a concept is
  complete and correct.  As you debug, you're reviewing and
  reinforcing the learning.

***** Drill down Method

****** Coverage

Get a map of the terrain.  Get a general sense of what you need to
learn.  This could mean watching lecture videos or reading textbooks.
How about the syllabus?  This is the least efficient stage.  Watch
videos at 1.5X or 2X speed.

Don't highlight books.  Instead take sparse notes while reading or do
a one paragraph summary after each major section.

****** Practice 

Practice problems are huge for boosting your understanding but there
are two efficiency traps if you're not careful.

- Not getting immediate feedback.  If you want to learn you need
  immediate feedback.  The best way is to go question by question with
  the answers in hand.  Finish a question and then check your answer.

- Grinding Problems - Practice problems should be used to highlight
  areas where you need to gain more understanding in.  See Feynman
  Technique in a bit.

So Scott is saying use Practice Problems but don't get bogged down in
them.  If you get stuck, brush up on the area where you got stuck.

****** Insight

The goal of coverage and practice questions is to get you to the point
where you know what you don't understand.  The Feynman Technique helps
you fill in the gaps in your knowledge.

***** The Feynman Technique

Richard Feynman describes himself struggling with a hard research
paper. His solution was to go meticulously through the supporting
material until he understood everything that was required to
understand the hard idea.

In other words, divide and conquer.  Digest the big idea that you
don't understand into little chunks that you can learn and understand
and then work your way back up to the big idea.

Steps:

- Get a piece of paper
- Write at the top the idea or process you want to understand.
- Explain the idea as if you were teaching it to someone else.

During step 3 youll get to a place where you can't explain something.
That's the precise gap in your understanding tha tyou need to fill.
Research the answer.  By narrowly defining your misunderstanding it
becomes easier to find the precise answer.

If you don't get the idea at all, copy the author's explanation but
try to elaborate and clarify it yourself.

For procedures explain each step, not only what it does but how to
execute it, and perhaps why.

For formulas, you should seek to understand them not just memorize
them.  If you see a formula you don't understand, break it down into
parts and try to understand the parts.

***** Developing Deeper Intuition

Most intuitions are one of the following types:

- Analogies - You notice a similarity between one thing and another
  (easier to understand) idea.
- Visulizations - making a mental picture of an abstract idea (even if its
  incomplete) helps.
- Simplifications - If you can explain something to your grandmother,
  you really understand it.  Simplification is the strengthening of
  connections between basic components and complex ideas.

Once you feel you understand a concept see if you can use one of the
above methods above to explain it.

** Version Control

*** git

** Web Frameworks

*** Client Side

**** Angular JS

*** Server Side

**** Play!


**** NodeJS

** Systems

*** Links

**** TODO [[https://en.wikipedia.org/wiki/Systems_thinking][Systems Thinking (Wikipedia)]]

** Simulations

#+OPTIONS: num:nil
   
