#+TITLE: Learning
* Introduction

This project is an experiment.  I'd like to add a bit more structure
to the things I know and the things I'm interested in learning about.
Maybe a notebook would be better; maybe not.

I'm not sure how I'm going to incorporate images and diagrams into
this notebook (to make it a more visual experience) but we'll see how
far I can get.

* Viewing on GitHub

I have not researched how to make all the links that work just fine in
org-mode in Emacs work at all on GitHub.  To best view this document,
clone this repo and open learning.org in Emacs (assuming you have
org-mode installed).

* Topics

These are some of the topics I'm interested in learning more about.

** Artificial Intelligence

*** Reinforcement Learning

**** Terms

- reward :: what the agent expects to receive in the short term for
            taking a particular action.  May be negative (punishment)
            or positive (actual reward).

- value :: what the agent expects to receive in the long term by
           executing its policy.

*** Neural Networks

*** Bayesian Networks

*** Books
**** "Artificial Intelligence, A Modern Approach" by Norvig, et al.

*** Key Challenge of Artificial Intelligence

To find out how to write programs that, to the extent possible,
produce rational behavior from a small amount of code rather than a
large number of table entries.

*** Agent Types

These agents types are defined in the terms section

**** Simple Reflex Agent

Pseudocode: [[./SimpleReflexAgent.hs][Source Code]]

**** Model Based Reflex Agent

Pseudocode: [[./ModelBasedAgent.hs][Source Code]]

**** Goal-Based Agent

Pseudocode: [[./GoalBasedAgent.hs][Source Code]]

**** Utility Based Agent

Pseudocode: [[./UtilityBasedAgent.hs][Source Code]]

*** Learning Agent

See Figure 2.15 on page 53

A learning agent has four conceptual components (defined further in terms section):

- Learning Element

- Critic

- Problem Generator

- Performance Element

*** Task Environment 

**** Fully Observable or Partially Observable

If the agent can observe everything there is to know about the
environment at all times, then the environment is fully observable,
otherwise it's partially observable.

**** Deterministic or Stochastic

If the next state of the environment is completely defined by the
current state of the environment and the next action of the agent,
then it is a deterministic environment.  See: strategic.

**** Episodic or Sequential

An environment is episodic when the agent acquires a percept, then
takes a single action based on the updated percept sequence.  This
process then repeats.  Importantly the next episode does not depend on
the actions taken during any previous episode.  Sounds like a Markov
Chain.  An example is detecting defects in a product on an assembly
line.

In a sequential environment the current decision can affect all future
decisions.  Some examples would be chess and taxi driving.

**** Static or Dynamic

If the environment can change while the agent is thinking then the
environment is dynamic.  If the environment is dynamic and it's
changing faster than the agent can decide what to do, the agent does
nothing.

If, in a static environment, the only thing that changes is the
agent's performance measure the environment is semidynamic.

**** Discrete or Continuous

Discreteness can be applied to several aspects of the task environment.

- Time - whether time passes in a continuous nature or not

- Percepts - the percepts the agent collects may be discrete or
  continuous.

- Actions - the actions that the agent takes may be discrete or
  continuous

- States - whether or not there are a finite number of states.

**** Single Agent or Multi Agent

Multiagent environments can be cooperative or competitive.

*** Terms
 
- agent :: something that perceives its environment using one or more
           sensors and acts upon its environment using one or more
           actuators.  An agent is a combination of the agent
           architecture and an agent program.

- agent architecture :: computing device with physical sensors and
     actuators.

- agent function :: a function that maps different percept sequences
                    to actions.  The agent function is computed at
                    three distinct times: when it is being designed,
                    when an action is being deliberated, and when the
                    agent learns, the agent function computes how to
                    modify the agent's behavior.

- agent program :: software that implements the agent function mapping
                   percepts into actions.

- actuator :: a way in which the agent interacts with its environment
              (e.g. robotic hands, computer display, etc.)

- critic :: a component of a learning agent that provides input on how
            well the agent is doing based on a fixed performance
            standard and determines how the performance element should
            be modified to do better in the future.  The standard used
            for critiquing actions must be fixed (i.e. the agent
            should not modify its critic to influence its behavior).

- condition-action rule :: A rule that states when a specific
     condition becomes true, a specific action should be taken.

- exploration :: an example of information gathering, often done to
                 gain information about an unfamiliar environment.

- goal-based agent :: an agent that has information about the goal it
     should acheive and is programmed to analyze the goal, and its
     model of the environment (if it's available) in order to select
     actions.  Sometimes goal-based action selection is easy (when the
     goal can be acheived in a single action).  Sometimes goal-based
     action selection is more tricky.  In these cases planning and
     search techniques can be used.  Goal-based agents are more
     flexible than agents that follow condition-action rules because
     the knowledge that supports its decisions is represented
     explicitly and can be updated.

- information gathering :: actions taken to modify futur percepts,
     often done by rational agents to increase their expected
     performance.

- learning element :: a component of a learning agent that is
     responsible for making improvements

- model :: information on how the world evolves independently of the
           agent's actions and how the agent's actions affect the
           world.  Combined these two information sets states "How the
           World Works" according to the agent.

- model-based reflex agent :: this agent keeps track of what it has
     observed in some internal state.  Updating this internal state
     requires two kinds of knowledge: 1) how the world evolves
     independently of the agent and 2) how the agent's actions affect
     the world.  Giving a simple reflex agent the ability to maintain
     and update state is the most effective way of handling partial
     observability.

- percept :: an agent's perceptual inputs at a given point in time.

- percept sequence :: the complete history of the agents observations
     (percepts).

- performance element :: a component of a learning agent that is
     responsible for selecting external actions.  The perforance
     element is what we have previously thought of as the whole agent.
     It's as if a learning agent is a regular agent along with some
     additional elements.  It takes percepts and decides actions.

- performance measure :: embodies the success criteria for the success
     of the agent.  It is better to derive the performance measures
     from what you actually want and not how you want the agent to
     behave.

- problem generator :: a component of a learning agent that suggests
     actions that will lead to new and informative experiences.  Helps
     the agent explore and avoid a potentially sub-optimal, greedy
     solution.

- rational agent :: an agent that always does the right thing Ivery
                    entry in the agent's table contains an action that
                    maximizes the agent' success.  A rational agent is
                    not a perfect agent.  Rationality maximizes
                    expected performance not actual performance.

- sensor :: A senor collects data, measurements, stimulus from the
            agent's environment.

- simple reflex agent :: an agent that selects its next action based
     entirely on the current percept, ignoring all previous percepts.
     These agents are simple but they are of limited intelligence.
     Even a little bit of limited observability can cause the simple
     reflex agent a lot of problems because they may ignore crucial
     information.  They are subject to infinte loops (oscilating
     between two states) but these loops can be broken out of by
     adding some randomness to the agent's agent function.

- strategic :: where the next state of the environment deterministic
               except for the actions of other agents.

- task environment :: the problem to which the agent is the solution.
     It is comprised of PEAS (Performance Measure, Environment,
     Actuators, and Sensors).

- utility-based agent :: An agent that uses a utility function to
     select its actions.  Goals alone are insufficient to produce
     high-quality behavior in most environments.  Goals can be in
     conflict.

- utility function :: A function maps a state (or sequence of states)
     to a number.  A utility function can help address the problem of
     conflicting goals (speed vs. safety).  When their are multiple
     goals, the agent can use the utility function to weigh expected
     performance of acheiving the goal against the likelihood of
     acheiving each goal.

*** Source Code

- [[./Agent.hs][Agent.hs]]

** Big Data
*** Hadoop
*** Cascading
** Cognitive Science
*** Books

**** "Brain Rules" by John Medina

**** "Now you See It" by Cathy Davidson

[[http://www.amazon.com/Now-You-See-Attention-Transform/dp/0670022829][On Amazon]]

** Computer Architecture
*** Memory Hierarchy
**** Registers
**** L1 Cache
**** L2 Cache
**** L3 Cache
**** Main Memory
**** Disk
**** Network
**** NUMA
**** MESI Protocol
**** Interconnect
**** Load/Store Buffers
**** Write Absorbtion

**** Times for Common Operations

Sources: [[http://surana.wordpress.com/2009/01/01/numbers-everyone-should-know/][Surana]], [[https://docs.google.com/viewer?url%3Dhttp%253A%252F%252Fsoftware.intel.com%252Fsites%252Fproducts%252Fcollateral%252Fhpc%252Fvtune%252Fperformance_analysis_guide.pdf][Intel]], [[http://norvig.com/21-days.html#answers][Peter Norvig]]

|-------------------------------------+------------------------+------------------+--------|
| Operation                           | Time (nanoseconds) <r> |   Alternate Unit | Cycles |
|-------------------------------------+------------------------+------------------+--------|
| <l>                                 |                    <r> |              <r> |    <r> |
| L1 cache reference                  |                 0.5 ns |                  |     ~4 |
| Exeute Instruction                  |                   1 ns |                  |        |
| Branch mispredict                   |                   5 ns |                  |        |
| L2 cache reference                  |                   7 ns |                  |    ~10 |
| Mutex lock/unlock                   |              25-100 ns |                  |        |
| Main memory reference               |                 100 ns |                  |        |
| Compress 1K bytes with Zippy        |              10,000 ns |  10 microseconds |        |
| Send 2K bytes over 1 Gbps network   |              20,000 ns |  20 microseconds |        |
| Read 1 MB sequentially from memory  |             250,000 ns | 250 microseconds |        |
| Round trip within same datacenter   |             500,000 ns | 500 microseconds |        |
| Fetch from new disk location (seek) |           8,000,000 ns |          8 msecs |        |
| Read 1 MB sequentially from network |          10,000,000 ns |         10 msecs |        |
| Read 1 MB sequentially from disk    |          20,000,000 ns |         20 msecs |        |
| Send packet CA->Netherlands->CA     |         150,000,000 ns |        150 msecs |        |
|-------------------------------------+------------------------+------------------+--------|

Other Metrics Of Interest

|------------------------------------------+----------------------|
| Metric                                   |                Value |
|------------------------------------------+----------------------|
| <l>                                      |                  <r> |
| Speed of Light                           | 186,000 miles/second |
| Circumference of Earth                   |         40,000 miles |
| Maximum Transmission Distance (on Earth) |         20,000 miles |
| Width of United States                   |          2,770 miles |
|------------------------------------------+----------------------|

*** Central Processing Unit
*** Networking
*** CUDA
*** Storage Drives
**** SSD
**** Hard Drive (Rotating)
** Databases

*** Relational

**** MySQL
**** PostgreSQL

*** NoSQL

**** Cassandra

***** Drivers

****** Java

******* [[https://github.com/datastax/java-driver][Official DataStax CQL Driver]]

- [[http://www.datastax.com/documentation/developer/java-driver/1.0/webhelp/index.html][Documentation]]
- [[http://www.datastax.com/drivers/java/apidocs/][API]]

**** MongoDB

** Data Structures
*** Analysis
**** Big O
**** Analytic Combinatorics
** Distributed Systems
*** Akka

Has its own section under [[Scala]].

*** Consensus
*** Vector Clocks
** Denotational Semantics
*** People
**** Conal Elliot

[[http://conal.net/][Home Page]]

** Emacs
*** Elisp
*** Packages
**** Org-Mode
***** LaTeX
****** Examples

- Summation - \sum x
- \exist x \rarr x = 0
- \forall x \rarr x \gt x
- 4 \div 2 =div  =  2
- \pi

****** Arrows

\Leftarrow (Leftarrow)      
\Leftrightarrow (Leftrightarrow)                                      
\Rightarrow (Rightarrow)          
\downarrow (downarrow)                                                                                                      
\hArr (hArr)                                                                                      
\harr (harr)                                                                                                                
\lArr (lArr)                
\uparrow (uparrow)        
\larr (larr)                      
\leftarrow (leftarrow)            
\leftrightarrow (leftrightarrow)    
\rArr (rArr)                
\rarr (rarr)                      
\rightarrow (rightarrow)                                      

****** Uncategorized 

\amp (amp)                                            
\approx (approx)                                                      
\because (because)                                                                                
\bullet (bullet)            
\cap (cap)                                                            
\cdots (cdots)                                                                                    
\circ (circ)                        
\colon (colon)              
\cong (cong)                                                          
\cup (cup)                          
\deg (deg)                          
\div (div)                  
\dots (dots)                                                          
\emptyset (emptyset)              
\equal (equal)                    
\equiv (equiv)                      
\exists (exists)            
\exp (exp)                        
\fnof (fnof)                        
\forall (forall)          
\frac12 (frac12)            
\frac14 (frac14)                  
\frac34 (frac34)                    
\frown (frown)              
\geq (geq)                  
\gets (gets)                                                          
\gt (gt)                  
\hellip (hellip)          
\in (in)                    
\infty (infty)            
\int (int)                                                                                        
\isin (isin)                                          
\lambda (lambda)                  
\land (land)                        
\lang (lang)              
\laquo (laquo)              
\le (le)                    
\leq (leq)                                            
\lg (lg)                                                                                                                    
\ln (ln)                  
\log (log)                                                                                        
\lor (lor)                                            
\lrm (lrm)                          
\lsquo (lsquo)              
\lt (lt)                          
\max (max)                                            
\micro (micro)                      
\middot (middot)          
\minus (minus)                    
\ne (ne)                            
\neg (neg)                
\neq (neq)                  
\ni (ni)                  
\not (not)                  
\notin (notin)                    
\nsub (nsub)                        
\nsup (nsup)                                                                                                                
\oplus (oplus)                      
\otimes (otimes)                                      
\partial (partial)                  
\perp (perp)              
\pi (pi)                                                              
\plus (plus)                
\plusmn (plusmn)                  
\prec (prec)                
\preccurlyeq (preccurlyeq)        
\preceq (preceq)                    
\prime (prime)            
\prod (prod)                
\radic (radic)                                                        
\rang (rang)              
\raquo (raquo)              
\real (real)                                                  
\rsaquo (rsaquo)                    
\rsquo (rsquo)                                                                                                              
\sdot (sdot)                                          
\setminus (setminus)                
\sim (sim)                          
\simeq (simeq)            
\sin (sin)                  
\sinh (sinh)                      
\slash (slash)                      
\sub (sub)                  
\sube (sube)                      
\subset (subset)                    
\succ (succ)              
\succcurlyeq (succcurlyeq)  
\succeq (succeq)                  
\sum (sum)                          
\sup (sup)                
\sup1 (sup1)                
\sup2 (sup2)                      
\sup3 (sup3)                        
\supe (supe)              
\supset (supset)                                              
\tan (tan)                          
\therefore (therefore)                                                                            
\theta (theta)                                                                                                              
\tilde (tilde)            
\times (times)              
\to (to)                          
\triangleq (triangleq)    
\varepsilon (varepsilon)                                                                                                    

**** Magit
**** Haskell-Mode
**** Yasnippet
**** ido
*** Tips & Tricks
** Emotionally Focused Therapy

*** Links 

- [[https://en.wikipedia.org/wiki/Emotionally_focused_therapy][on Wikipedia]]

** Fault Tolerance
*** Terms

- failure :: When the delivered service no longer complies with the specification.  If there is no specification, there can be no failure. Failures are observed by the user of the system.  Failures are caused by errors.

- error :: An incorrect system behavior that may cause a failure. Errors fall into two categories: timing and value.  Value errors can take the form of incorrect state or an incorrect discrete value. Errors can be detected before they cause failures.  Errors are the manifestation of faults.  The presence of errors implies the presence of faults.

- fault :: a defect in a system that can cause an error.  Faults can be caused by incorrect requirements, coding defects, incorrect designs, etc.  A fault that is not causing any errors is latent.

- latent :: A fault that is not causing any errors is latent.

- active :: A fault that causes an error is active.

- fail-silent :: a system that presents the correct result or no result at all.

- crash-failure :: the system stops after it detects an error

*** Bad Assumptions

- Only one error occurs at a time
- One error is recovered from  before the next one occurs
- Each error is independent from each other error

*** Fault -> Error -> Failure

*** Books
**** [[http://techbus.safaribooksonline.com/book/software-engineering-and-development/patterns/9780470319796][Patterns for Fault Tolerant Software]] by Robert S. Hanmer
** Functional Programming 
*** Lambda Calculus

*** Functional Data Structures
** Information Theory
   
*** Entropy
*** Compression
** Learning

** Machine Learning

*** Links

- [ ] [[http://www.kaggle.com/][Kaggle]]

*** Supervised Learning


**** Decision Trees

**** Naive Bayesian Classifier

*** Unsupervised Learning


**** Clustering

*** Ensemble Methods
*** Boosting
*** Tools

**** Weka

***** Links
 
- [[http://www.cs.waikato.ac.nz/ml/weka/][Home Page]]

** Mathematics
*** Algebra
*** Linear Algebra
*** Discrete Math
**** Books
***** "Concrete Mathematics" by Donald Knuth, et al.
*** Euler's Constant
*** Causality
**** Books
***** "Causality" by Judea Pearl
*** Abstract Algebra
*** Probability
*** Statistics
*** Distance Metrics
*** Graph Theory
*** Proofs

** Operating Systems
*** Concepts
**** Virtual Memory
**** Devices
**** Networking
**** Security
**** Troubleshooting
**** Optimizing
*** Linux

*** FreeBSD
    
** Programming Environments

*** Java Virtual Machine

*** .NET Runtime

I'm pretty much focusing on the JVM for now.


** Programming Languages

*** Java
    
**** Features

***** NIO
      
***** Lambdas

***** Concurrency


**** Tools

***** Maven

****** Build Life Cycle

- default :: handles project deployment

- clean :: handles cleaning of your project

- site :: handles creation of your project's site documentation

****** Phases of the default lifecycle

- validate :: validate the project is correct and all necessary
              information is available

- compile :: compile the source code of the project

- test :: test the compiled source code using a suitable unit testing
          framework. These tests /should not require the code be
          packaged/ or deployed

- package :: take the compiled code and package it in its
             distributable format, such as a JAR.

- integration-test :: process and deploy the package if necessary into
     an environment where integration tests can be run

- verify :: run any checks to verify the package is valid and meets
            quality criteria

- install :: install the package into the local repository, for use as
             a dependency in other projects locally

- deploy :: done in an integration or release environment, copies the
            final package to the remote repository for sharing with
            other developers and projects.

****** Links

- [[https://maven.apache.org/guides/index.html][Documentation]]

*** Scala

**** Links

- [[http://docs.scala-lang.org/][Home Page]]
- [[http://www.scala-lang.org/api/current/#package][ScalaDocs (Current)]]

**** Macros

**** *Akka

***** Links 

- [[http://akka.io][Home Page]]

- [[http://doc.akka.io/docs/akka/2.2.1/scala.html][Scala Documentation]]

- [[http://doc.akka.io/api/akka/2.2.1/][ScalaDocs]]

***** Concepts

- Actor System :: a hierarchical group of actors which share common
                  configuration.  It is also used for looking up
                  actors.

**** scalaz

*** Haskell

**** Links

- [[http://www.haskell.org/haskellwiki/Haskell][Haskell Home Page]]
- [[http://book.realworldhaskell.org/read/][Real World Haskell]]
- [[http://learnyouahaskell.com/chapters][Learn You a Haskell]]
- [[http://www.haskell.org/ghc/docs/latest/html/libraries/index.html][Libraries Documentation]]
- [[http://themonadreader.wordpress.com/][The Monad.Reader]]
- [[http://planet.haskell.org/][Planet Haskell]]

**** To Read [0%] [0/14]

- [ ] [[./yaht.pdf][Yet Another Haskell Tutorial]]
- [ ] [[./HR.pdf][Haskell Road to Logic Math and Programming]]
- [ ] [[http://en.wikibooks.org/wiki/Haskell][Haskell Wiki Book]] ([[./HaskellWikibook.pdf][PDF]])
- [ ] [[http://www.haskell.org/haskellwiki/Hitchhikers_guide_to_Haskell][Hitchhiker's Guide to Haskell]]
- [ ] [[./awkward-squad.pdf][Tackling the Awkward Squad]]
- [ ] [[http://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours][Write Yourself a Scheme in 48 Hours]]
- [ ] [[http://www.haskell.org/haskellwiki/Scrap_your_boilerplate][Scrap Your Boilerplate]]
- [ ] [[./HPR.pdf][Higher-order + Polymorphic = Reuse]]
- [ ] [[./whyfp.pdf][Why Functional Programming]]
- [ ] [[./monads2arrows.pdf][Generalizing Monads to Arrows]]
- [ ] [[./arrows_robots.pdf][Arrows, Robots, and FRP]]
- [ ] [[./edsl.pdf][Building Domain-Specific Embedded Languages]]
- [ ] [[./monad_interpreter.pdf][Build a Monadic Interpreter]]
- [ ] [[http://www.haskell.org/haskellwiki/Category:Style][Haskell Style Wiki Category]]
- [ ] [[http://www.haskell.org/haskellwiki/Emacs][Emacs & Haskell]]
- [ ] [[http://www.haskell.org/haskellwiki/How_to_write_a_Haskell_program][How to Write a Haskell Program]]
- [ ] [[http://www.haskell.org/ghc/docs/latest/html/users_guide/index.html][GHC/GHCI Manual]]
- [ ] [[http://www.haskell.org/haskellwiki/Research_papers/Functional_pearls][Functional Pearls]]
- [ ] [[http://www.haskell.org/haskellwiki/Research_papers/Data_structures][Research Papers on Data Structures]]
- [ ] [[http://www.haskell.org/haskellwiki/Research_papers/Top_10][Top Research Papers]]
- [ ] [[http://www.scs.stanford.edu/11au-cs240h/notes/][Lecture Notes from Stanford's Haskell Course]]
  
**** Concurrency
**** Arrows
**** Monoids
**** MonadPlus
**** Lenses

*** C++

**** Lambda Expressions

**** Concurrency
     
**** Concepts (next version)
**** Templates

*** Python

**** Idioms

**** Pandas

**** IPython

**** SciKit-Learn
     
**** Generators
**** The with keyword

*** Other
**** Prolog
***** Difference Lists
***** Natural Language Processing
**** ML
***** Side-Effects
**** Javascript
** Software Architecture
** Ultra Learning

*** Links [66%] [2/3]

**** TODO [[./scott_young.pdf][Scott's Book on Learning]]

**** DONE [[http://www.scotthyoung.com/blog/2011/09/01/learn-faster/][The Feynman Technique]]

**** DONE [[http://calnewport.com/blog/2012/10/26/mastering-linear-algebra-in-10-days-astounding-experiments-in-ultra-learning/][Interview with Scott Young]]

The method you use to learn matters lot.  Deeper levels of processing
can double your efficiency.

Cramming does not work at MIT; courses build on each other.

Deepening Understanding is made up of two things:

- Making Connections - connections provide context
- Debugging Errors - make sure your understanding of a concept is
  complete and correct.  As you debug, you're reviewing and
  reinforcing the learning.

***** Drill down Method

****** Coverage

Get a map of the terrain.  Get a general sense of what you need to
learn.  This could mean watching lecture videos or reading textbooks.
How about the syllabus?  This is the least efficient stage.  Watch
videos at 1.5X or 2X speed.

Don't highlight books.  Instead take sparse notes while reading or do
a one paragraph summary after each major section.

****** Practice 

Practice problems are huge for boosting your understanding but there
are two efficiency traps if you're not careful.

- Not getting immediate feedback.  If you want to learn you need
  immediate feedback.  The best way is to go question by question with
  the answers in hand.  Finish a question and then check your answer.

- Grinding Problems - Practice problems should be used to highlight
  areas where you need to gain more understanding in.  See Feynman
  Technique in a bit.

So Scott is saying use Practice Problems but don't get bogged down in
them.  If you get stuck, brush up on the area where you got stuck.

****** Insight

The goal of coverage and practice questions is to get you to the point
where you know what you don't understand.  The Feynman Technique helps
you fill in the gaps in your knowledge.

***** The Feynman Technique

Richard Feynman describes himself struggling with a hard research
paper. His solution was to go meticulously through the supporting
material until he understood everything that was required to
understand the hard idea.

In other words, divide and conquer.  Digest the big idea that you
don't understand into little chunks that you can learn and understand
and then work your way back up to the big idea.

Steps:

- Get a piece of paper
- Write at the top the idea or process you want to understand.
- Explain the idea as if you were teaching it to someone else.

During step 3 youll get to a place where you can't explain something.
That's the precise gap in your understanding tha tyou need to fill.
Research the answer.  By narrowly defining your misunderstanding it
becomes easier to find the precise answer.

If you don't get the idea at all, copy the author's explanation but
try to elaborate and clarify it yourself.

For procedures explain each step, not only what it does but how to
execute it, and perhaps why.

For formulas, you should seek to understand them not just memorize
them.  If you see a formula you don't understand, break it down into
parts and try to understand the parts.

***** Developing Deeper Intuition

Most intuitions are one of the following types:

- Analogies - You notice a similarity between one thing and another
  (easier to understand) idea.
- Visulizations - making a mental picture of an abstract idea (even if its
  incomplete) helps.
- Simplifications - If you can explain something to your grandmother,
  you really understand it.  Simplification is the strengthening of
  connections between basic components and complex ideas.

Once you feel you understand a concept see if you can use one of the
above methods above to explain it.

** Version Control

*** git

** Web Frameworks
*** Client Side
**** Angular JS
*** Server Side
**** Play!

** Systems
*** Links
**** TODO [[https://en.wikipedia.org/wiki/Systems_thinking][Systems Thinking (Wikipedia)]]
** Simulations  



#+OPTIONS: num:nil

